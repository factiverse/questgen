hyper parameters:
  evaluation_strategy: "epoch"
  learning_rate: 2e-5
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  weight_decay: 0.3
  num_train_epochs: 100
  predict_with_generate: true
  fp16: true
  overwrite_output_dir: true
  no_cuda: false

data: data/sample
output_dir: models/
model_checkpoint: "t5-small-finetuned-xsum"
wandb_tags: ["query generation", "question generation"]

metrics:
  rouge: true
  bleu: true