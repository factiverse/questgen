import os
import json
import csv

# import random

# all_names = []
# all_data = []
# for d in os.listdir("./data"):
#     if d != 'sample':
#         all_names.append("data/"+d)

# for i in all_names:
#     with open(str(i)+"/test.json",'r') as f:
#         data = json.load(f)
#         random.shuffle(data)
#     with open(str(i)+"/test-10.json", 'w') as file:
#         json.dump(data[:int(len(data)/10)], file, indent=4)
#     print(len(data), len(data[:int(len(data)/10)]), int(len(data)/10), int(len(data)/10) == len(data[:int(len(data)/10)]))
# # with open("data/all_test/test.json", 'w') as file:
# #     json.dump(all_data, file, indent=4)

# TODO: Please go through all the .json files in ZeroShot and all the models and generate a table from that (probbably in csv format) so that it is more easily viewable
# TODO: Choose 100 in total claims from all the datasets and look at the claims generated by the models to see how it performs. Go though the results and rate the response on a scale from 1-5 for how well the model performed on that specific claim

for m in os.listdir("./models"):
    data = {}
    r = os.path.join("./models", str(m))
    for f in os.listdir(r):
        f = str(f.strip())
        if f.endswith(".json"):
            print(f)
            with open(os.path.join(r, f), "r") as file:
                d = json.load(file)
                data[f.split(".json")[0]] = d[0]
                print(type(d[0]))
    with open(os.path.join("./src/table", m) + ".csv", "w") as file:
        dw = csv.DictWriter(
            file, list(data[list(data.keys())[0]].keys()) + ["name"]
        )
        dw.writeheader()
        for k, v in data.items():
            # k = [k]
            # v = list(v)
            # v.append(k)
            v["name"] = k
            print(type(v), type(k))
            dw.writerow(v)
